{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 本程序给出SnowNLP的简单用法\n",
    "\n",
    "----\n",
    "\n",
    "更多例子见：\n",
    "1. https://pypi.python.org/pypi/snownlp/0.12.3\n",
    "\n",
    "2. https://github.com/isnowfy/snownlp\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.分词功能（比jieba略差，推荐使用jieba进行分词）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SnowNLP', '是', '一个', 'python', '写', '的', '类库', '，', '可以', '方便', '的', '处理', '中文', '文本', '内容', '，', '是', '受到', '了', 'TextBlob', '的', '启发', '而', '写', '的', '，', '由于', '现在', '大部分', '的', '自然语言', '处理', '库', '基本', '都', '是', '针对', '英文', '的', '，', '于是', '写', '了', '一个', '方便', '处理', '中文', '的', '类库', '，', '并且', '和', 'TextBlob', '不同', '的', '是', '，', '这里', '没有', '用', 'NLTK', '，', '所有', '的', '算法', '都', '是', '自己', '实现', '的', '，', '并且', '自带', '了', '一些', '训练', '好', '的', '字典']\n",
      "\n",
      "-------------------------\n",
      "\n",
      "['SnowNLP', '是', '一个', 'python', '写', '的类', '库', '，', '可以', '方便', '的', '处理', '中文', '文本', '内容', '，', '是', '受到', '了', 'TextBlob', '的', '启发', '而', '写', '的', '，', '由于', '现在', '大部分', '的', '自然', '语言', '处理', '库', '基本', '都', '是', '针对', '英文', '的', '，', '于是', '写', '了', '一个', '方便', '处理', '中文', '的类', '库', '，', '并且', '和', 'TextBlob', '不同', '的', '是', '，', '这里', '没有', '用', 'NLTK，', '所有', '的', '算法', '都', '是', '自己', '实现', '的', '，', '并且', '自', '带', '了', '一些', '训练', '好', '的', '字典']\n"
     ]
    }
   ],
   "source": [
    "from snownlp import SnowNLP\n",
    "import jieba\n",
    "\n",
    "'''1.分词功能（比jieba略差，推荐使用jieba进行分词）'''\n",
    "\n",
    "testString=\"SnowNLP是一个python写的类库，可以方便的处理中文文本内容，是受到了TextBlob的启发而写的，由于现在大部分的自然语言处理库基本都是针对英文的，于是写了一个方便处理中文的类库，并且和TextBlob不同的是，这里没有用NLTK，所有的算法都是自己实现的，并且自带了一些训练好的字典\"\n",
    "cutWork1=list(jieba.cut(testString))\n",
    "print(cutWork1)\n",
    "print('\\n-------------------------\\n')\n",
    "curWork2=SnowNLP(testString).words\n",
    "print(curWork2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.词性标注"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('SnowNLP', 'Dg'), ('是', 'v'), ('一个', 'm'), ('python', 'q'), ('写', 'v'), ('的类', 'h'), ('库', 'n'), ('，', 'w'), ('可以', 'v'), ('方便', 'a'), ('的', 'u'), ('处理', 'v'), ('中文', 'nz'), ('文本', 'n'), ('内容', 'n'), ('，', 'w'), ('是', 'v'), ('受到', 'v'), ('了', 'u'), ('TextBlob', 'a'), ('的', 'u'), ('启发', 'vn'), ('而', 'c'), ('写', 'v'), ('的', 'u')]\n"
     ]
    }
   ],
   "source": [
    "testString1=\"SnowNLP是一个python写的类库，可以方便的处理中文文本内容，是受到了TextBlob的启发而写的\"\n",
    "\n",
    "tag=list(SnowNLP(testString1).tags)\n",
    "print(tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.断句"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SnowNLP是一个python写的类库', '可以方便的处理中文文本内容', '是受到了TextBlob的启发而写的']\n"
     ]
    }
   ],
   "source": [
    "sentences=list(SnowNLP(testString1).sentences)\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.情绪判断(对英文的处理效果不好)\n",
    "\n",
    "- 返回值为正面情绪的概率，\n",
    "\n",
    "- 越接近1表示正面情绪\n",
    "\n",
    "- 越接近0表示负面情绪"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text1:  0.08032424324970644\n",
      "text2:  0.9531216798451757\n",
      "text3:  0.7117029223494293\n",
      "text4:  0.6948221395657904\n",
      "text5:  0.5\n",
      "text6:  0.3669724770642201\n",
      "text7:  0.16368193611936954\n"
     ]
    }
   ],
   "source": [
    "text1=\"这个人脾气真心不好，老是骂人\"\n",
    "text2=\"这个人给人的感觉不错，经常笑\"\n",
    "text3=\"这家伙给人感觉一般般\"\n",
    "text4=\"你是个好人\"\n",
    "text5=\"你真坏\"\n",
    "text6=\"为什么你这么不要脸\"\n",
    "text7=\"I love you\"\n",
    "print('text1: ',SnowNLP(text1).sentiments)\n",
    "print('text2: ',SnowNLP(text2).sentiments)\n",
    "print('text3: ',SnowNLP(text3).sentiments)\n",
    "print('text4: ',SnowNLP(text4).sentiments)\n",
    "print('text5: ',SnowNLP(text5).sentiments)\n",
    "print('text6: ',SnowNLP(text6).sentiments)\n",
    "print('text7: ',SnowNLP(text7).sentiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.拼音"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['zhe', 'ge', 'ren', 'gei', 'ren', 'de', 'gan', 'jue', 'bu', 'cuo', '，', 'jing', 'chang', 'xiao']\n"
     ]
    }
   ],
   "source": [
    "testString3=\"这个人给人的感觉不错，经常笑\"\n",
    "pinyinNote=SnowNLP(testString3).pinyin\n",
    "print(pinyinNote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.繁体转简体"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "雪国观光圈是由7个乡镇所组成。一年之中有将近半年的时间，都被大雪所封闭。\n"
     ]
    }
   ],
   "source": [
    "testString4=\"雪國觀光圈是由7個鄉鎮所組成。一年之中有將近半年的時間，都被大雪所封閉。\"\n",
    "hanzi=SnowNLP(testString4).han\n",
    "print(hanzi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.关键词抽取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['小姑娘', '奶奶', '顶用', '丝绒', '喜欢', '小', '做', '红帽', '送给', '开']\n"
     ]
    }
   ],
   "source": [
    "testString5='''\n",
    "从前有个可爱的小姑娘，谁见了都喜欢，但最喜欢她的是她的奶奶，因为不论她\n",
    "要什么，奶奶就会给她什么。一次，奶奶送给小姑娘一顶用丝绒做的小红帽，戴\n",
    "在她的头上可好看了。从此，小姑娘再也不愿意戴任何别的帽子，于是大家便开\n",
    "始叫她小红帽\n",
    "'''\n",
    "keywords=SnowNLP(testString5).keywords(limit=10)\n",
    "print(keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.概括总结文意"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['奶奶送给小姑娘一顶用丝绒做的小红帽', '但最喜欢她的是她的奶奶', '小姑娘再也不愿意戴任何别的帽子']\n"
     ]
    }
   ],
   "source": [
    "summary=SnowNLP(testString5).summary(limit=3)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.文本相似性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4686473612532025, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "s = SnowNLP([['这篇', '文章'],\n",
    "                ['那篇', '论文'],\n",
    "                ['这个']])\n",
    "\n",
    "\n",
    "sim= s.sim(['文章'])\n",
    "print(sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.信息量衡量\n",
    "\n",
    "-------\n",
    "\n",
    "TF-IDF是一种统计方法，用以评估一字词对于一个文件集或一个语料库中的其中一份文件的重要程度。\n",
    "\n",
    "TF词频越大越重要，但是文中会的“的”，“你”等无意义词频很大，却信息量几乎为0，这种情况导致单纯看词频评\n",
    "\n",
    "价词语重要性是不准确的。因此加入了IDF,IDF的主要思想是：如果包含词条t的文档越少，也就是n越小，IDF\n",
    "\n",
    "越大，则说明词条t越重要。TF-IDF综合起来，才能准确的综合的评价一词对文本的重要性。\n",
    "\n",
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'文章': 1, '这篇': 1}, {'那篇': 1, '论文': 1}, {'这个': 1}]\n",
      "{'那篇': 0.5108256237659907, '这个': 0.5108256237659907, '文章': 0.5108256237659907, '这篇': 0.5108256237659907, '论文': 0.5108256237659907}\n"
     ]
    }
   ],
   "source": [
    "print(s.tf)\n",
    "print(s.idf)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
